# Bo√Æte √† outils de science des donn√©es orient√©e objet (ds_toolkit)

**Cours :** Master en Science des Donn√©es - Programmation Orient√©e Objet  
**Devoir :** Projet Final & Devoir √† la Maison

## Vue d'ensemble du projet

Ce projet refactorise du code de science des donn√©es proc√©dural en un package orient√© objet robuste, modulaire et r√©utilisable (`ds_toolkit`). Il d√©montre l'application de principes avanc√©s de g√©nie logiciel aux flux de travail de science des donn√©es, y compris les mod√®les de conception, les tests unitaires et une structure de package solide.

## üìã Fonctionnalit√©s & Respect des Exigences

Cette soumission r√©pond √† toutes les exigences du devoir √† la maison :

1.  **Structure compl√®te du package** :
    - Code source organis√© dans le r√©pertoire `ds_toolkit/`.
    - `setup.py` inclus pour l'installation (`pip install -e .`).
    - S√©paration claire des pr√©occupations (Nettoyage, Pipeline, Validation).

2.  **Mod√®les de conception impl√©ment√©s** :
    - **Mod√®le Fa√ßade** (`ds_toolkit/facade.py`) : La classe `DataSciencePackage` fournit une interface simplifi√©e et unifi√©e pour l'ensemble du flux de travail (Nettoyage -> Mod√©lisation), masquant la complexit√© √† l'utilisateur.
    - **Mod√®le Strat√©gie** (`ds_toolkit/cross_validation.py`) : `CrossValidationStrategy` permet de changer dynamiquement d'algorithme de validation (par ex., `KFold`, `StratifiedKFold`) sans modifier le contexte.
    - **Mod√®le D√©corateur** (`ds_toolkit/utils.py`) : `logging_decorator` et `timing_decorator` √©tendent le comportement des fonctions (journalisation, profilage) sans modifier le code source.
    - **M√©thode Mod√®le** (Implicite dans `DataCleaner`) : La m√©thode `clean()` d√©finit le squelette de l'op√©ration de nettoyage, appelant des √©tapes sp√©cifiques dans l'ordre.

3.  **Documentation compl√®te** :
    - Ce README fournit des instructions d'installation, d'utilisation et des d√©tails architecturaux.
    - Le code est document√© avec des docstrings.

4.  **Tests unitaires** :
    - Tests situ√©s dans le r√©pertoire `tests/`.
    - Couvre la logique de nettoyage des donn√©es et l'orchestration du pipeline.
    - Ex√©cuter via `python -m unittest discover tests`.

## üìÇ Structure du Projet

```
.
‚îú‚îÄ‚îÄ ds_toolkit/                # Package Python Main
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Exporte les classes cl√©s
‚îÇ   ‚îú‚îÄ‚îÄ cleaning.py            # Module de Nettoyage de Donn√©es (DataCleaner)
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py            # Module Pipeline ML (Loader, Splitter, Scaler, Model)
‚îÇ   ‚îú‚îÄ‚îÄ cross_validation.py    # Strat√©gies de Validation Crois√©e
‚îÇ   ‚îú‚îÄ‚îÄ validation.py          # Framework de Validation de Donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ facade.py              # Point d'Entr√©e Principal (Fa√ßade)
‚îÇ   ‚îî‚îÄ‚îÄ utils.py               # Utilitaires & D√©corateurs
‚îú‚îÄ‚îÄ tests/                     # Suite de Tests Unitaires
‚îÇ   ‚îú‚îÄ‚îÄ test_cleaning.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py
‚îú‚îÄ‚îÄ exercise_*.py              # Scripts d'exercices originaux (pour r√©f√©rence)
‚îú‚îÄ‚îÄ setup.py                   # Fichier d'installation du package
‚îî‚îÄ‚îÄ README.md                  # Documentation du Projet
```

## üöÄ Installation

Pour installer le package en mode √©ditable (recommand√© pour le d√©veloppement) :

```bash
pip install -e .
```

## üíª Exemples d'Utilisation

### 1. Le "Bouton Facile" (Mod√®le Fa√ßade)

Le moyen le plus simple d'ex√©cuter une analyse compl√®te est d'utiliser la Fa√ßade :

```python
from ds_toolkit.facade import DataSciencePackage

# Initialiser
pkg = DataSciencePackage(filepath='customer_churn.csv', target_col='Churn')

# Tout ex√©cuter : charger -> nettoyer -> entra√Æner -> √©valuer
pkg.run_full_workflow()
```

### 2. Construction Personnalis√©e de Pipeline

Pour plus de contr√¥le, vous pouvez composer des composants individuels :

```python
from ds_toolkit.cleaning import DataCleaner
from ds_toolkit.pipeline import MLPipeline, DataLoader, DataSplitter, Scaler, ModelHandler

# 1. Nettoyer les Donn√©es
cleaner = DataCleaner('raw_data.csv')
cleaner.clean()
cleaner.save_data('clean_data.csv')

# 2. Construire le Pipeline
pipeline = MLPipeline(
    loader=DataLoader('clean_data.csv', target_column='target'),
    splitter=DataSplitter(test_size=0.2),
    scaler=Scaler(),
    model_handler=ModelHandler(n_estimators=200)
)

# 3. Ex√©cuter
pipeline.run()
```

### 3. Utilisation des D√©corateurs

```python
from ds_toolkit.utils import timing_decorator

@timing_decorator
def heavy_computation():
    # ... code ...
    pass
```

## üß™ Ex√©cution des Tests

Ex√©cutez la suite de tests pour vous assurer que tout fonctionne :

```bash
python -m unittest discover tests
```

## üìä D√©tails de Conception

### Nettoyage de Donn√©es (`cleaning.py`)

Encapsule toute la logique de nettoyage. Des m√©thodes comme `remove_duplicates` et `handle_missing_values` retournent `self` pour permettre le cha√Ænage de m√©thodes (style Interface Fluide).

### Pipeline ML (`pipeline.py`)

Suit les principes **SOLID**. Le `MLPipeline` d√©pend d'abstractions (typage canard en Python) plut√¥t que d'impl√©mentations concr√®tes, ce qui vous permet d'√©changer facilement des √©l√©ments comme le mod√®le ou le scaler.

### Validation (`validation.py`)

Un framework extensible o√π vous pouvez ajouter de nouvelles classes `ValidationRule` (Principe Ouvert/Ferm√©) sans modifier le validateur principal.
